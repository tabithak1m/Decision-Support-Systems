{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN-7-GtIezuO",
        "outputId": "0136d622-294b-412f-8fe4-2c6bc355087b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=7f17bf64362e0f796e15de7cef4e7b9cb76923af50f0f6e38978b68ebcdf43d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting scikit-learn==1.5\n",
            "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5) (3.5.0)\n",
            "Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.5.2\n",
            "    Uninstalling scikit-learn-1.5.2:\n",
            "      Successfully uninstalled scikit-learn-1.5.2\n",
            "Successfully installed scikit-learn-1.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "!pip install scikit-learn==1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZxVJZ-xUeD5a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import wget\n",
        "import time as time\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "#your import here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hsJJfFMjobL"
      },
      "source": [
        "## Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1jWjWJtWjobL",
        "outputId": "c41eaeec-a832-4522-9cd7-1bc038a0b31e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sale_data (1).zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "wget.download('https://github.com/MIE451-2024/course-datasets/raw/refs/heads/main/sale_data.zip', 'sale_data.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4VSdRu3jobM",
        "outputId": "49d16ce9-10cb-4c4e-ad80-63dd9cb8d0cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sale_data.zip\n",
            "replace __MACOSX/._sale_data? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!unzip sale_data.zip\n",
        "DATA_DIR = 'sale_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v7CtXcwRjobM"
      },
      "outputs": [],
      "source": [
        "# get the train dataset (this data is the training data used to train your model, traing data will be same as in our evaluation)\n",
        "train_data = pd.read_csv(DATA_DIR+\"/train_data_assignment.csv\")\n",
        "# get a sample test dataset (the final test data will be different in our evaluation)\n",
        "test_data = pd.read_csv(DATA_DIR+\"/test_data_assignment.csv\")\n",
        "# weather data (optional)\n",
        "weather_data = pd.read_csv(DATA_DIR+\"/weather_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADc_uPjnjobN"
      },
      "source": [
        "## Q4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebXJMPamjobN"
      },
      "outputs": [],
      "source": [
        "# You can use theis code block to test different models and hyperparameters using train_data\n",
        "# The autograder will only retreived the functions defined below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mPdbg9bVjobN"
      },
      "outputs": [],
      "source": [
        "def data_cleaning(raw_data, weather_data = None):\n",
        "    # This function should handle the cleaning of the dataset for both training and testing\n",
        "\n",
        "    # DO NOT modify the name or drop the 'Sales' column when cleaning the training set\n",
        "\n",
        "    # This function also be able to handle cleaning test dataset, which does not have 'Sales' column\n",
        "    clean_data = raw_data.copy()\n",
        "    ################# YOU CODE HERE ################\n",
        "    datetime_cols = clean_data.select_dtypes(include=['datetime64']).columns\n",
        "    for col in datetime_cols:\n",
        "        clean_data[col] = pd.to_datetime(clean_data[col], format='%Y-%m-%d')\n",
        "        clean_data[f'{col}_Year'] = clean_data[col].dt.year\n",
        "        clean_data[f'{col}_Month'] = clean_data[col].dt.month\n",
        "        clean_data[f'{col}_Day'] = clean_data[col].dt.day\n",
        "        clean_data.drop(columns=[col], inplace=True)\n",
        "\n",
        "    categorical_cols = clean_data.select_dtypes(include=['object']).columns\n",
        "    clean_data = pd.get_dummies(clean_data, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "    if 'Sales' in clean_data.columns:\n",
        "        clean_data['Sales'] = clean_data['Sales'].fillna(0)  # Handle missing Sales data\n",
        "\n",
        "    clean_data = clean_data.fillna(0)\n",
        "\n",
        "    if weather_data is not None and 'State' in clean_data.columns:\n",
        "        clean_data = clean_data.merge(weather_data, on='State', how='left')\n",
        "\n",
        "    # the return dataset should be a dataframe\n",
        "    # that was cleaned and ready to be used for either training or testing\n",
        "    return clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "e5vtRfCjjobN"
      },
      "outputs": [],
      "source": [
        "def train_model(train_data):\n",
        "    # Split the data into observed features and target feature\n",
        "    X = train_data.drop(['Sales'], axis=1)\n",
        "    y = train_data['Sales']\n",
        "\n",
        "\n",
        "    ################# YOU CODE HERE ################\n",
        "    # You should:\n",
        "    # 1. Create your best model and store in the model variable\n",
        "    # 2. Train your model with the train data where X is the observed features and y is the target feature\n",
        "\n",
        "    # base_model = linear_model.Ridge()\n",
        "    # param_grid = {'alpha': [0.1,1,5]}  # Values of alpha from 0.001 to 1000\n",
        "\n",
        "    # # Use GridSearchCV to find the best alpha using cross-validation\n",
        "    # scorer = make_scorer(root_mean_squared_error, greater_is_better=False)  # RMSE scorer\n",
        "    # grid_search = GridSearchCV(estimator=base_model, param_grid=param_grid, scoring=scorer, cv=5)\n",
        "\n",
        "    # # Fit the model on the training data\n",
        "    # grid_search.fit(X, y)\n",
        "\n",
        "    # # Get the best model after tuning alpha\n",
        "    # model = grid_search.best_estimator_\n",
        "\n",
        "    '''\n",
        "    model = linear_model.Ridge(alpha = 5.5)\n",
        "    rmse = cross_val_score(model, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
        "    mean_rmse = np.mean(np.sqrt(-rmse))\n",
        "    model.fit(X, y)\n",
        "    '''\n",
        "    '''\n",
        "    model = linear_model.Ridge(5.5)\n",
        "    model.fit(X,y)\n",
        "    '''\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = xgb.XGBRegressor(\n",
        "        n_estimators=150,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        objective='reg:squarederror',\n",
        "        random_state=42,\n",
        "        alpha=5,\n",
        "        gamma=1,\n",
        "        reg_lambda=1\n",
        "        )\n",
        "\n",
        "    # rmse = cross_val_score(model, X, y, cv=3, scoring='neg_root_mean_squared_error')\n",
        "    # mean_rmse = np.mean(np.sqrt(-rmse))\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    train_rmse = np.sqrt(root_mean_squared_error(y_train, y_train_pred))\n",
        "    # print(f'Training RMSE: {train_rmse:.4f}')\n",
        "\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    rmse = np.sqrt(root_mean_squared_error(y_val, y_val_pred))\n",
        "    # print(f'Validation RMSE: {rmse:.4f}')\n",
        "\n",
        "    # the model return by this function should be ready to predict the sales given the test data\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3DGmXBxLjobN"
      },
      "outputs": [],
      "source": [
        "def prediction(train_data, test_data):\n",
        "    # This function should return the prediction given the test dataset\n",
        "    # The output should be a dataframe with one column\n",
        "    # and the index should match the test_data index\n",
        "    train_data = data_cleaning(raw_data = train_data, weather_data = weather_data) #make sure the returned train data as the same order of rows as the train data\n",
        "    model = train_model(train_data) # This will run the train_model your implemented above to obtain a trained model\n",
        "    test_data = data_cleaning(raw_data = test_data, weather_data = weather_data) #make sure the returned test data as the same order of rows as the train data\n",
        "\n",
        "    # check if the test data has all the columns that the model was trained on\n",
        "    for column in train_data.columns:\n",
        "        if column not in test_data.columns and column != 'Sales':\n",
        "            # add the missing column to the test data and set it to 0\n",
        "            #  (feel free to change it to any other value)\n",
        "            test_data[column] = 0\n",
        "\n",
        "    # Ensure the order of the columns in the test dataset is the same as the train\n",
        "    test_data = test_data[[column for column in train_data.columns if column != 'Sales']]\n",
        "\n",
        "    ################# YOU CODE HERE ################\n",
        "    # You should use 'model' to make predictions\n",
        "    y_pred = model.predict(test_data) # Please store the prediction of test data in y_pred\n",
        "\n",
        "    # the return should be a dataframe with one column and the index should match test_data index\n",
        "    return pd.DataFrame(y_pred, columns=['Sales'], index=test_data.index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrx8rEvGjobN",
        "outputId": "09d21211-f67a-42b4-8d6a-b2e7f00c5a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 880.897338960675\n"
          ]
        }
      ],
      "source": [
        "# This is the sample code for our autograder to eveluate your model, you should make sure the code is working as expected\n",
        "\n",
        "# This will be a sample test dataset to help you validate your code, the actual test dataset will be different\n",
        "X_test = test_data.drop('Sales', axis=1)\n",
        "# This will be target value that you will compare with your prediction (you will not have this in the test set)\n",
        "y_test = test_data['Sales']\n",
        "\n",
        "# THE RUNTIME FOR FOLLOWING CODE SHOULD BE WITHIN 7 MINUTES\n",
        "y_pred = prediction(train_data, X_test)\n",
        "\n",
        "# This will print the RMSE score for the test dataset\n",
        "print(f\"RMSE: {root_mean_squared_error(y_test, y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHBvL0QRjobN"
      },
      "source": [
        "A clear and concise description of your chosen feature set and any additional features you used through feature engineering or external sources.\n",
        "\n",
        "Coverted date-based features to datetime format (year, month, day), one hot encoded categorial features, integrated weather data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHHZWtwYjobN"
      },
      "source": [
        "The name of the regression model you choose:\n",
        "\n",
        "XGBoost Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXnc9BHsjobO"
      },
      "source": [
        "Why you chose the feature set and model?\n",
        "\n",
        "Feature Set:\n",
        "- Extracted date time features to better encapture patterns\n",
        "\n",
        "Model:\n",
        "- Chose since there were three regularization hyperparamters that could be tuned\n",
        "- Lowest rmse due to model's flexibility for non-linear relationships"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}